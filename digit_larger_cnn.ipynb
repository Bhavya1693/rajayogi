{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled4.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rajayogi/rajayogi/blob/master/digit_larger_cnn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "1Pqj6KHKAdZF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "20560374-7db5-43c4-8b31-3905ee1f597d"
      },
      "cell_type": "code",
      "source": [
        "# Larger CNN for the MNIST Dataset\n",
        "import numpy\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import Flatten\n",
        "from keras.layers.convolutional import Conv2D\n",
        "from keras.layers.convolutional import MaxPooling2D\n",
        "from keras.utils import np_utils\n",
        "from keras import backend as K\n",
        "K.set_image_dim_ordering('th')\n",
        "# fix random seed for reproducibility\n",
        "seed = 7\n",
        "numpy.random.seed(seed)\n",
        "# load data\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "# reshape to be [samples][pixels][width][height]\n",
        "X_train = X_train.reshape(X_train.shape[0], 1, 28, 28).astype('float32')\n",
        "X_test = X_test.reshape(X_test.shape[0], 1, 28, 28).astype('float32')\n",
        "# normalize inputs from 0-255 to 0-1\n",
        "X_train = X_train / 255\n",
        "X_test = X_test / 255\n",
        "# one hot encode outputs\n",
        "y_train = np_utils.to_categorical(y_train)\n",
        "y_test = np_utils.to_categorical(y_test)\n",
        "num_classes = y_test.shape[1]"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "X1KOPuoOAeuK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# define the larger model\n",
        "def larger_model():\n",
        "\t# create model\n",
        "\tmodel = Sequential()\n",
        "\tmodel.add(Conv2D(30, (5, 5), input_shape=(1, 28, 28), activation='relu'))\n",
        "\tmodel.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\tmodel.add(Conv2D(15, (3, 3), activation='relu'))\n",
        "\tmodel.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\tmodel.add(Dropout(0.2))\n",
        "\tmodel.add(Flatten())\n",
        "\tmodel.add(Dense(128, activation='relu'))\n",
        "\tmodel.add(Dense(50, activation='relu'))\n",
        "\tmodel.add(Dense(num_classes, activation='softmax'))\n",
        "\t# Compile model\n",
        "\tmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\treturn model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4fRt1H4pAkcY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 558
        },
        "outputId": "e0e686d8-7af1-4fe0-f3c1-a90dcded8ab5"
      },
      "cell_type": "code",
      "source": [
        "# build the model\n",
        "model = larger_model()\n",
        "# Fit the model\n",
        "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=200)\n",
        "# Final evaluation of the model\n",
        "scores = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(\"Large CNN Error: %.2f%%\" % (100-scores[1]*100))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 67s 1ms/step - loss: 0.3911 - acc: 0.8809 - val_loss: 0.0899 - val_acc: 0.9705\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 67s 1ms/step - loss: 0.1002 - acc: 0.9696 - val_loss: 0.0550 - val_acc: 0.9822\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 68s 1ms/step - loss: 0.0744 - acc: 0.9772 - val_loss: 0.0417 - val_acc: 0.9861\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 67s 1ms/step - loss: 0.0619 - acc: 0.9811 - val_loss: 0.0380 - val_acc: 0.9870\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 67s 1ms/step - loss: 0.0529 - acc: 0.9832 - val_loss: 0.0343 - val_acc: 0.9889\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 67s 1ms/step - loss: 0.0455 - acc: 0.9854 - val_loss: 0.0283 - val_acc: 0.9906\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 67s 1ms/step - loss: 0.0399 - acc: 0.9877 - val_loss: 0.0313 - val_acc: 0.9897\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 67s 1ms/step - loss: 0.0362 - acc: 0.9883 - val_loss: 0.0263 - val_acc: 0.9912\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 67s 1ms/step - loss: 0.0329 - acc: 0.9898 - val_loss: 0.0224 - val_acc: 0.9928\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 67s 1ms/step - loss: 0.0305 - acc: 0.9908 - val_loss: 0.0253 - val_acc: 0.9920\n",
            "Large CNN Error: 0.80%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "5gGMLR3YAo1N",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}